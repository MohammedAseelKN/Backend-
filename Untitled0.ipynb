{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install deepface\n",
        "!pip install librosa\n",
        "!pip install scikit-learn\n",
        "!pip install pydub\n",
        "!pip install kagglehub\n",
        "!pip install imbalanced-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJsiuTBCes5M",
        "outputId": "bef9ee47-f8c2-437c-adf7-a07a680e9e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Collecting deepface\n",
            "  Downloading deepface-0.0.93-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.67.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (11.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.11.0.86)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.18.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.8.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.1.0)\n",
            "Collecting flask-cors>=4.0.1 (from deepface)\n",
            "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.4.0->deepface) (2.5.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (3.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn>=20.1.0->deepface) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface)\n",
            "  Downloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2025.1.31)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (3.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Downloading deepface-0.0.93-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.6/108.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Downloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=3a47c3da4827e1c5616ba445ffc8ffa12a696aab5bcb455c524f146e050780c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: lz4, gunicorn, fire, mtcnn, flask-cors, retina-face, deepface\n",
            "Successfully installed deepface-0.0.93 fire-0.7.0 flask-cors-5.0.0 gunicorn-23.0.0 lz4-4.4.3 mtcnn-1.0.0 retina-face-0.0.17\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.7)\n",
            "Requirement already satisfied: model-signing in /usr/local/lib/python3.11/dist-packages (from kagglehub) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from model-signing->kagglehub) (43.0.3)\n",
            "Requirement already satisfied: in-toto-attestation in /usr/local/lib/python3.11/dist-packages (from model-signing->kagglehub) (0.9.3)\n",
            "Requirement already satisfied: sigstore in /usr/local/lib/python3.11/dist-packages (from model-signing->kagglehub) (3.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from model-signing->kagglehub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->model-signing->kagglehub) (1.17.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from in-toto-attestation->model-signing->kagglehub) (4.25.6)\n",
            "Requirement already satisfied: id>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sigstore->model-signing->kagglehub) (1.5.0)\n",
            "Requirement already satisfied: pyasn1~=0.6 in /usr/local/lib/python3.11/dist-packages (from sigstore->model-signing->kagglehub) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from sigstore->model-signing->kagglehub) (2.10.6)\n",
            "Requirement already satisfied: pyjwt>=2.1 in /usr/local/lib/python3.11/dist-packages (from sigstore->model-signing->kagglehub) (2.10.1)\n",
            "Requirement already satisfied: pyOpenSSL>=23.0.0 in /usr/local/lib/python3.11/dist-packages (from sigstore->model-signing->kagglehub) (24.2.1)\n",
            "Requirement already satisfied: rich~=13.0 in /usr/local/lib/python3.11/dist-packages (from sigstore->model-signing->kagglehub) (13.9.4)\n",
            "Requirement already satisfied: rfc8785~=0.1.2 in /usr/local/lib/python3.11/dist-packages (from sigstore->model-signing->kagglehub) (0.1.4)\n",
            "Requirement already satisfied: rfc3161-client~=0.1.2 in /usr/local/lib/python3.11/dist-packages (from sigstore->model-signing->kagglehub) (0.1.2)\n",
            "Requirement already satisfied: sigstore-protobuf-specs==0.3.2 in /usr/local/lib/python3.11/dist-packages (from sigstore->model-signing->kagglehub) (0.3.2)\n",
            "Requirement already satisfied: sigstore-rekor-types==0.0.18 in /usr/local/lib/python3.11/dist-packages (from sigstore->model-signing->kagglehub) (0.0.18)\n",
            "Requirement already satisfied: tuf~=5.0 in /usr/local/lib/python3.11/dist-packages (from sigstore->model-signing->kagglehub) (5.1.0)\n",
            "Requirement already satisfied: platformdirs~=4.2 in /usr/local/lib/python3.11/dist-packages (from sigstore->model-signing->kagglehub) (4.3.6)\n",
            "Requirement already satisfied: betterproto==2.0.0b6 in /usr/local/lib/python3.11/dist-packages (from sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (2.0.0b6)\n",
            "Requirement already satisfied: grpclib<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (0.4.7)\n",
            "Requirement already satisfied: python-dateutil<3.0,>=2.8 in /usr/local/lib/python3.11/dist-packages (from betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->model-signing->kagglehub) (2.22)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->sigstore->model-signing->kagglehub) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->sigstore->model-signing->kagglehub) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich~=13.0->sigstore->model-signing->kagglehub) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich~=13.0->sigstore->model-signing->kagglehub) (2.18.0)\n",
            "Requirement already satisfied: securesystemslib~=1.0 in /usr/local/lib/python3.11/dist-packages (from tuf~=5.0->sigstore->model-signing->kagglehub) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich~=13.0->sigstore->model-signing->kagglehub) (0.1.2)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pydantic[email]<3,>=2->sigstore-rekor-types==0.0.18->sigstore->model-signing->kagglehub) (2.2.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->pydantic[email]<3,>=2->sigstore-rekor-types==0.0.18->sigstore->model-signing->kagglehub) (2.7.0)\n",
            "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (4.2.0)\n",
            "Requirement already satisfied: multidict in /usr/local/lib/python3.11/dist-packages (from grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (6.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0,>=2.8->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (1.17.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (4.1.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import pipeline\n",
        "from deepface import DeepFace\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Function to upload audio and image files manually\n",
        "def upload_files():\n",
        "    from google.colab import files\n",
        "    uploaded_files = files.upload()\n",
        "    file_paths = list(uploaded_files.keys())\n",
        "    return file_paths\n",
        "\n",
        "# Function to get text emotion score\n",
        "def get_text_emotion_score(text):\n",
        "    nlp = pipeline('sentiment-analysis')\n",
        "    result = nlp(text)\n",
        "    text_score = result[0]['score'] if result[0]['label'] == 'POSITIVE' else 1 - result[0]['score']\n",
        "    return float(text_score), result[0]['label']\n",
        "\n",
        "# Function to get audio emotion score\n",
        "def get_audio_emotion_score(audio_path, clf):\n",
        "    y, sr = librosa.load(audio_path)\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr).T, axis=0)\n",
        "    features = np.hstack([mfccs, chroma, mel])\n",
        "    # Predict using the pre-trained classifier\n",
        "    emotion_prediction = clf.predict([features])\n",
        "    audio_score = float(emotion_prediction[0])  # Get the predicted score and convert to float\n",
        "    return audio_score\n",
        "\n",
        "# Function to get facial emotion scores\n",
        "def get_facial_emotion_scores(image_path):\n",
        "    results = DeepFace.analyze(img_path=image_path, actions=['emotion'])\n",
        "    if isinstance(results, dict):  # Single face detected\n",
        "        return [results['emotion']]\n",
        "    elif isinstance(results, list):  # Multiple faces detected\n",
        "        return [res['emotion'] for res in results]\n",
        "\n",
        "# Function to normalize facial emotion scores\n",
        "def normalize_facial_scores(scores_list):\n",
        "    combined_scores = {}\n",
        "    for scores in scores_list:\n",
        "        for emotion, score in scores.items():\n",
        "            if emotion not in combined_scores:\n",
        "                combined_scores[emotion] = 0.0  # Initialize with float type\n",
        "            combined_scores[emotion] += float(score)  # Convert score to float\n",
        "\n",
        "    # Calculate average for each emotion\n",
        "    num_faces = len(scores_list)\n",
        "    for emotion in combined_scores:\n",
        "        combined_scores[emotion] /= num_faces\n",
        "\n",
        "    # Find the dominant emotion and its score\n",
        "    dominant_emotion = max(combined_scores, key=combined_scores.get)\n",
        "    dominant_emotion_score = combined_scores[dominant_emotion]\n",
        "    return dominant_emotion_score, dominant_emotion\n",
        "\n",
        "# Function to integrate all emotion scores\n",
        "def integrate_emotion_scores(text, audio_path, image_path, clf):\n",
        "    # Fetch scores from text, audio, and facial analysis\n",
        "    text_score, text_emotion = get_text_emotion_score(text)\n",
        "    audio_score = get_audio_emotion_score(audio_path, clf)\n",
        "    facial_score, facial_emotion = normalize_facial_scores(get_facial_emotion_scores(image_path))\n",
        "\n",
        "    # Combine text, audio, and facial scores\n",
        "    combined_score = (text_score + audio_score + facial_score) / 3\n",
        "\n",
        "    # Find the emotion category with the highest score\n",
        "    return combined_score, {\n",
        "        'text': text_emotion, 'audio': audio_score, 'facial': facial_emotion\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "# Upload audio and image files manually\n",
        "file_paths = upload_files()\n",
        "\n",
        "# Assign the paths accordingly\n",
        "text_input = \"I'm feeling great today!\"\n",
        "audio_path = [file for file in file_paths if file.endswith('.m4a')][0]  # Replace with your audio file path\n",
        "image_path = [file for file in file_paths if file.endswith('.jpg') or file.endswith('.png')][0]  # Replace with your image file path\n",
        "\n",
        "# Download the RAVDESS dataset using KaggleHub\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"uwrfkaggler/ravdess-emotional-speech-audio\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Load and process the RAVDESS dataset\n",
        "import os\n",
        "\n",
        "def process_audio(file_path):\n",
        "    y, sr = librosa.load(file_path)\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr).T, axis=0)\n",
        "    return np.hstack([mfccs, chroma, mel])\n",
        "\n",
        "mfcc_features = []\n",
        "labels = []\n",
        "\n",
        "for root, _, files in os.walk(path):\n",
        "    for filename in files:\n",
        "        if filename.endswith(\".wav\"):\n",
        "            file_path = os.path.join(root, filename)\n",
        "            mfcc_features.append(process_audio(file_path))\n",
        "            emotion = filename.split('-')[2]  # Assuming labels are in the filename\n",
        "            labels.append(int(emotion))  # Ensure labels are integers\n",
        "\n",
        "mfcc_features = np.array(mfcc_features)\n",
        "labels = np.array(labels)\n",
        "print(\"MFCC Features Shape:\", mfcc_features.shape)\n",
        "print(\"Labels Shape:\", labels.shape)\n",
        "\n",
        "# Balance the dataset using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(mfcc_features, labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Integrate emotion scores\n",
        "final_emotion_score, emotions = integrate_emotion_scores(text_input, audio_path, image_path, clf)\n",
        "\n",
        "# Print the final emotion scores and categories\n",
        "print(f\"Final Emotion Score: {final_emotion_score}\")\n",
        "print(f\"Emotions: {emotions}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "MLsRiqqhmJ1j",
        "outputId": "362af57b-f12d-4301-9f92-11f06d04afb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eaad59ba-9efd-48e3-9a9e-718435f70feb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eaad59ba-9efd-48e3-9a9e-718435f70feb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving New recording 4.m4a to New recording 4 (3).m4a\n",
            "Saving WhatsApp Image 2025-02-16 at 16.32.55_695e5447.jpg to WhatsApp Image 2025-02-16 at 16.32.55_695e5447 (3).jpg\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/uwrfkaggler/ravdess-emotional-speech-audio/versions/1\n",
            "MFCC Features Shape: (2880, 180)\n",
            "Labels Shape: (2880,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9349593495934959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Emotion Score: 34.666069070465106\n",
            "Emotions: {'text': 'POSITIVE', 'audio': 3.0, 'facial': 'happy'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import pipeline\n",
        "from deepface import DeepFace\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Function to upload audio and image files manually\n",
        "def upload_files():\n",
        "    from google.colab import files\n",
        "    uploaded_files = files.upload()\n",
        "    file_paths = list(uploaded_files.keys())\n",
        "    return file_paths\n",
        "\n",
        "# Function to get text emotion score\n",
        "def get_text_emotion_score(text):\n",
        "    nlp = pipeline('sentiment-analysis')\n",
        "    result = nlp(text)\n",
        "    text_score = result[0]['score'] if result[0]['label'] == 'POSITIVE' else 1 - result[0]['score']\n",
        "    return float(text_score), result[0]['label']\n",
        "\n",
        "# Function to get audio emotion score\n",
        "def get_audio_emotion_score(audio_path, clf):\n",
        "    y, sr = librosa.load(audio_path)\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr).T, axis=0)\n",
        "    features = np.hstack([mfccs, chroma, mel])\n",
        "    # Predict using the pre-trained classifier\n",
        "    emotion_prediction = clf.predict([features])\n",
        "    audio_score = float(emotion_prediction[0])  # Get the predicted score and convert to float\n",
        "    return audio_score\n",
        "\n",
        "# Function to get facial emotion scores\n",
        "def get_facial_emotion_scores(image_path):\n",
        "    results = DeepFace.analyze(img_path=image_path, actions=['emotion'])\n",
        "    if isinstance(results, dict):  # Single face detected\n",
        "        return [results['emotion']]\n",
        "    elif isinstance(results, list):  # Multiple faces detected\n",
        "        return [res['emotion'] for res in results]\n",
        "\n",
        "# Function to normalize facial emotion scores\n",
        "def normalize_facial_scores(scores_list):\n",
        "    combined_scores = {}\n",
        "    for scores in scores_list:\n",
        "        for emotion, score in scores.items():\n",
        "            if emotion not in combined_scores:\n",
        "                combined_scores[emotion] = 0.0  # Initialize with float type\n",
        "            combined_scores[emotion] += float(score)  # Convert score to float\n",
        "\n",
        "    # Calculate average for each emotion\n",
        "    num_faces = len(scores_list)\n",
        "    for emotion in combined_scores:\n",
        "        combined_scores[emotion] /= num_faces\n",
        "\n",
        "    # Find the dominant emotion and its score\n",
        "    dominant_emotion = max(combined_scores, key=combined_scores.get)\n",
        "    dominant_emotion_score = combined_scores[dominant_emotion]\n",
        "    return dominant_emotion_score, dominant_emotion\n",
        "\n",
        "# Function to integrate all emotion scores\n",
        "def integrate_emotion_scores(text, audio_path, image_path, clf):\n",
        "    # Fetch scores from text, audio, and facial analysis\n",
        "    text_score, text_emotion = get_text_emotion_score(text)\n",
        "    audio_score = get_audio_emotion_score(audio_path, clf)\n",
        "    facial_score, facial_emotion = normalize_facial_scores(get_facial_emotion_scores(image_path))\n",
        "\n",
        "    # Combine text, audio, and facial scores\n",
        "    combined_score = (text_score + audio_score + facial_score) / 3\n",
        "\n",
        "    # Find the emotion category with the highest score\n",
        "    emotion_scores = {\n",
        "        'text_score': text_score,\n",
        "        'audio_score': audio_score,\n",
        "        'facial_score': facial_score\n",
        "    }\n",
        "    emotion_labels = {\n",
        "        'text_score': text_emotion,\n",
        "        'audio_score': 'predicted_audio_emotion',  # Placeholder for actual audio emotion\n",
        "        'facial_score': facial_emotion\n",
        "    }\n",
        "    final_emotion = emotion_labels[max(emotion_scores, key=emotion_scores.get)]\n",
        "\n",
        "    return combined_score, final_emotion\n",
        "\n",
        "# Define emotion-to-task mapping\n",
        "emotion_to_task = {\n",
        "    'happy': ['Take on a new project', 'Collaborate with a colleague', 'Lead a brainstorming session'],\n",
        "    'sad': ['Focus on a familiar task', 'Take a short break', 'Listen to music'],\n",
        "    'neutral': ['Continue with current tasks', 'Organize your workspace', 'Plan your day'],\n",
        "    'angry': ['Take a deep breath', 'Go for a walk', 'Write down your thoughts'],\n",
        "    'fear': ['Identify the source of fear', 'Discuss with a mentor', 'Engage in a calming activity'],\n",
        "    'disgust': ['Clean your workspace', 'Take a break from the task', 'Reflect on positive experiences'],\n",
        "    'surprise': ['Share the news with a colleague', 'Take a moment to process', 'Celebrate the surprise']\n",
        "}\n",
        "\n",
        "# Function to recommend tasks based on detected emotion\n",
        "def recommend_tasks(emotion):\n",
        "    # Recommend tasks based on the detected emotion\n",
        "    recommended_tasks = emotion_to_task.get(emotion, ['No specific tasks available'])\n",
        "\n",
        "    return recommended_tasks\n",
        "\n",
        "# Example usage\n",
        "# Upload audio and image files manually\n",
        "file_paths = upload_files()\n",
        "\n",
        "# Assign the paths accordingly\n",
        "text_input = \"I'm feeling great today!\"\n",
        "audio_path = [file for file in file_paths if file.endswith('.m4a')][0]  # Replace with your audio file path\n",
        "image_path = [file for file in file_paths if file.endswith('.jpg') or file.endswith('.png')][0]  # Replace with your image file path\n",
        "\n",
        "# Download the RAVDESS dataset using KaggleHub\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"uwrfkaggler/ravdess-emotional-speech-audio\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Load and process the RAVDESS dataset\n",
        "import os\n",
        "\n",
        "def process_audio(file_path):\n",
        "    y, sr = librosa.load(file_path)\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr).T, axis=0)\n",
        "    return np.hstack([mfccs, chroma, mel])\n",
        "\n",
        "mfcc_features = []\n",
        "labels = []\n",
        "\n",
        "for root, _, files in os.walk(path):\n",
        "    for filename in files:\n",
        "        if filename.endswith(\".wav\"):\n",
        "            file_path = os.path.join(root, filename)\n",
        "            mfcc_features.append(process_audio(file_path))\n",
        "            emotion = filename.split('-')[2]  # Assuming labels are in the filename\n",
        "            labels.append(int(emotion))  # Ensure labels are integers\n",
        "\n",
        "mfcc_features = np.array(mfcc_features)\n",
        "labels = np.array(labels)\n",
        "print(\"MFCC Features Shape:\", mfcc_features.shape)\n",
        "print(\"Labels Shape:\", labels.shape)\n",
        "\n",
        "# Balance the dataset using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(mfcc_features, labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Integrate emotion scores and get the detected emotion\n",
        "final_emotion_score, final_emotion = integrate_emotion_scores(text_input, audio_path, image_path, clf)\n",
        "print(f\"Final Emotion Score: {final_emotion_score}\")\n",
        "print(f\"Final Emotion: {final_emotion}\")\n",
        "\n",
        "# Recommend tasks based on the detected emotion\n",
        "recommended_tasks = recommend_tasks(final_emotion)\n",
        "print(f\"Recommended Tasks for '{final_emotion}': {recommended_tasks}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "eF_HkPdbr6rb",
        "outputId": "91701dd8-be88-434b-8779-d7b7cecbcc2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f988b85a-ac40-414b-bf8e-bce03048d484\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f988b85a-ac40-414b-bf8e-bce03048d484\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving New recording 4.m4a to New recording 4 (5).m4a\n",
            "Saving WhatsApp Image 2025-02-16 at 16.32.55_695e5447.jpg to WhatsApp Image 2025-02-16 at 16.32.55_695e5447 (5).jpg\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/uwrfkaggler/ravdess-emotional-speech-audio/versions/1\n",
            "MFCC Features Shape: (2880, 180)\n",
            "Labels Shape: (2880,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9512195121951219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Emotion Score: 34.666069070465106\n",
            "Final Emotion: happy\n",
            "Recommended Tasks for 'happy': ['Take on a new project', 'Collaborate with a colleague', 'Lead a brainstorming session']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "# Create a sample data frame to simulate mood data collection\n",
        "data = {\n",
        "    \"employee_id\": ['employee_1', 'employee_1', 'employee_1', 'employee_2', 'employee_2', 'employee_2'],\n",
        "    \"timestamp\": [\n",
        "        \"2025-02-10 08:00:00\", \"2025-02-11 08:00:00\", \"2025-02-12 08:00:00\",\n",
        "        \"2025-02-10 08:00:00\", \"2025-02-11 08:00:00\", \"2025-02-12 08:00:00\"\n",
        "    ],\n",
        "    \"emotion_score\": [0.8, 0.6, 0.7, 0.5, 0.9, 0.4],\n",
        "    \"emotion\": ['happy', 'neutral', 'happy', 'sad', 'happy', 'sad']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample Data Frame:\")\n",
        "print(df)\n",
        "\n",
        "# Function to analyze mood data for a specific employee\n",
        "def analyze_mood_data(df, employee_id):\n",
        "    employee_data = df[df['employee_id'] == employee_id]\n",
        "    return employee_data\n",
        "\n",
        "# Function to provide insights into long-term well-being based on mood trends\n",
        "def provide_insights(employee_data, employee_id):\n",
        "    avg_score = employee_data['emotion_score'].mean()\n",
        "    most_frequent_emotion = employee_data['emotion'].mode()[0]\n",
        "\n",
        "    print(f\"\\nInsights for {employee_id}:\")\n",
        "    print(f\"- Average Mood Score: {avg_score:.2f}\")\n",
        "    print(f\"- Most Frequent Emotion: {most_frequent_emotion}\")\n",
        "\n",
        "# Example usage of the integrated system\n",
        "\n",
        "# Analyze and provide insights for employee_1\n",
        "employee_1_data = analyze_mood_data(df, 'employee_1')\n",
        "provide_insights(employee_1_data, 'employee_1')\n",
        "\n",
        "# Analyze and provide insights for employee_2\n",
        "employee_2_data = analyze_mood_data(df, 'employee_2')\n",
        "provide_insights(employee_2_data, 'employee_2')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC_dDESgMVRb",
        "outputId": "7ff55ea9-ed87-4389-cb79-7e0b78c7737b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Data Frame:\n",
            "  employee_id            timestamp  emotion_score  emotion\n",
            "0  employee_1  2025-02-10 08:00:00            0.8    happy\n",
            "1  employee_1  2025-02-11 08:00:00            0.6  neutral\n",
            "2  employee_1  2025-02-12 08:00:00            0.7    happy\n",
            "3  employee_2  2025-02-10 08:00:00            0.5      sad\n",
            "4  employee_2  2025-02-11 08:00:00            0.9    happy\n",
            "5  employee_2  2025-02-12 08:00:00            0.4      sad\n",
            "\n",
            "Insights for employee_1:\n",
            "- Average Mood Score: 0.70\n",
            "- Most Frequent Emotion: happy\n",
            "\n",
            "Insights for employee_2:\n",
            "- Average Mood Score: 0.60\n",
            "- Most Frequent Emotion: sad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample data frame to simulate mood data collection with prolonged stress for employee_2\n",
        "data = {\n",
        "    \"employee_id\": ['employee_1', 'employee_1', 'employee_1', 'employee_2', 'employee_2', 'employee_2', 'employee_2', 'employee_2', 'employee_2'],\n",
        "    \"timestamp\": [\n",
        "        \"2025-02-10 08:00:00\", \"2025-02-11 08:00:00\", \"2025-02-12 08:00:00\",\n",
        "        \"2025-02-10 08:00:00\", \"2025-02-11 08:00:00\", \"2025-02-12 08:00:00\",\n",
        "        \"2025-02-13 08:00:00\", \"2025-02-14 08:00:00\", \"2025-02-15 08:00:00\"\n",
        "    ],\n",
        "    \"emotion_score\": [0.8, 0.6, 0.7, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4],\n",
        "    \"emotion\": ['happy', 'neutral', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Updated Sample Data Frame:\")\n",
        "print(df)\n",
        "\n",
        "# Function to analyze mood data for a specific employee\n",
        "def analyze_mood_data(df, employee_id):\n",
        "    employee_data = df[df['employee_id'] == employee_id]\n",
        "    return employee_data\n",
        "\n",
        "# Function to detect prolonged stress or disengagement\n",
        "def detect_stress(employee_data, threshold=0.5, prolonged_days=3):\n",
        "    # Convert timestamp to datetime using .loc to avoid SettingWithCopyWarning\n",
        "    employee_data.loc[:, 'timestamp'] = pd.to_datetime(employee_data['timestamp'])\n",
        "    # Sort data by timestamp\n",
        "    employee_data = employee_data.sort_values('timestamp')\n",
        "\n",
        "    # Identify days with emotion scores below the threshold\n",
        "    stressed_days = employee_data[employee_data['emotion_score'] < threshold]\n",
        "\n",
        "    # Check if prolonged stress or disengagement is detected\n",
        "    if len(stressed_days) >= prolonged_days:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# Function to send notifications to HR or managers (console-based notification)\n",
        "def send_notification(employee_id):\n",
        "    print(f\"Notification: Prolonged stress detected for {employee_id}. Notifying HR...\")\n",
        "\n",
        "# Example usage for employee_1\n",
        "employee_1_data = analyze_mood_data(df, 'employee_1')\n",
        "if detect_stress(employee_1_data):\n",
        "    send_notification('employee_1')\n",
        "\n",
        "# Example usage for employee_2\n",
        "employee_2_data = analyze_mood_data(df, 'employee_2')\n",
        "if detect_stress(employee_2_data):\n",
        "    send_notification('employee_2')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhqZfl-_K_Sh",
        "outputId": "e02a0a09-ba6d-420c-b012-4b89b4752add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Sample Data Frame:\n",
            "  employee_id            timestamp  emotion_score  emotion\n",
            "0  employee_1  2025-02-10 08:00:00            0.8    happy\n",
            "1  employee_1  2025-02-11 08:00:00            0.6  neutral\n",
            "2  employee_1  2025-02-12 08:00:00            0.7    happy\n",
            "3  employee_2  2025-02-10 08:00:00            0.4      sad\n",
            "4  employee_2  2025-02-11 08:00:00            0.4      sad\n",
            "5  employee_2  2025-02-12 08:00:00            0.4      sad\n",
            "6  employee_2  2025-02-13 08:00:00            0.4      sad\n",
            "7  employee_2  2025-02-14 08:00:00            0.4      sad\n",
            "8  employee_2  2025-02-15 08:00:00            0.4      sad\n",
            "Notification: Prolonged stress detected for employee_2. Notifying HR...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "\n",
        "# Create a sample data frame to simulate mood data collection with prolonged stress for employee_2\n",
        "data = {\n",
        "    \"employee_id\": ['employee_1', 'employee_1', 'employee_1', 'employee_2', 'employee_2', 'employee_2', 'employee_2', 'employee_2', 'employee_2'],\n",
        "    \"timestamp\": [\n",
        "        \"2025-02-10 08:00:00\", \"2025-02-11 08:00:00\", \"2025-02-12 08:00:00\",\n",
        "        \"2025-02-10 08:00:00\", \"2025-02-11 08:00:00\", \"2025-02-12 08:00:00\",\n",
        "        \"2025-02-13 08:00:00\", \"2025-02-14 08:00:00\", \"2025-02-15 08:00:00\"\n",
        "    ],\n",
        "    \"emotion_score\": [0.8, 0.6, 0.7, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4],\n",
        "    \"emotion\": ['happy', 'neutral', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Updated Sample Data Frame:\")\n",
        "print(df)\n",
        "\n",
        "# Function to analyze mood data for a specific employee\n",
        "def analyze_mood_data(df, employee_id):\n",
        "    employee_data = df[df['employee_id'] == employee_id]\n",
        "    return employee_data\n",
        "\n",
        "# Function to detect prolonged stress or disengagement\n",
        "def detect_stress(employee_data, threshold=0.5, prolonged_days=3):\n",
        "    # Convert timestamp to datetime using .loc to avoid SettingWithCopyWarning\n",
        "    employee_data.loc[:, 'timestamp'] = pd.to_datetime(employee_data['timestamp'])\n",
        "    # Sort data by timestamp\n",
        "    employee_data = employee_data.sort_values('timestamp')\n",
        "\n",
        "    # Identify days with emotion scores below the threshold\n",
        "    stressed_days = employee_data[employee_data['emotion_score'] < threshold]\n",
        "\n",
        "    # Check if prolonged stress or disengagement is detected\n",
        "    if len(stressed_days) >= prolonged_days:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# Function to send email\n",
        "def send_email(to_email, subject, message):\n",
        "    from_email = \"mohammedkn1302@gmail.com\"\n",
        "    from_password = \"aseelbhavana\"  # Use App Password if 2FA is enabled\n",
        "\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] = from_email\n",
        "    msg['To'] = to_email\n",
        "    msg['Subject'] = subject\n",
        "\n",
        "    msg.attach(MIMEText(message, 'plain'))\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP('smtp.gmail.com', 587)  # Gmail's SMTP server address\n",
        "        server.starttls()\n",
        "        server.login(from_email, from_password)\n",
        "        text = msg.as_string()\n",
        "        server.sendmail(from_email, to_email, text)\n",
        "        server.quit()\n",
        "        print(f\"Email sent to {to_email}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to send email. Error: {e}\")\n",
        "\n",
        "# Function to send alerts to HR or managers\n",
        "def send_alert(employee_id):\n",
        "    hr_email = \"mohammedaseel0786@gmail.com\"  # Replace with HR's email address\n",
        "    subject = f\"Prolonged Stress Alert for {employee_id}\"\n",
        "    message = f\"Alert: Prolonged stress detected for {employee_id}. Please take necessary actions.\"\n",
        "    send_email(hr_email, subject, message)\n",
        "\n",
        "# Example usage for employee_1\n",
        "employee_1_data = analyze_mood_data(df, 'employee_1')\n",
        "if detect_stress(employee_1_data):\n",
        "    send_alert('employee_1')\n",
        "\n",
        "# Example usage for employee_2\n",
        "employee_2_data = analyze_mood_data(df, 'employee_2')\n",
        "if detect_stress(employee_2_data):\n",
        "    send_alert('employee_2')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npheGwLiLmtn",
        "outputId": "a9bfd61d-b346-4951-d3ac-d54a5b1a5fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Sample Data Frame:\n",
            "  employee_id            timestamp  emotion_score  emotion\n",
            "0  employee_1  2025-02-10 08:00:00            0.8    happy\n",
            "1  employee_1  2025-02-11 08:00:00            0.6  neutral\n",
            "2  employee_1  2025-02-12 08:00:00            0.7    happy\n",
            "3  employee_2  2025-02-10 08:00:00            0.4      sad\n",
            "4  employee_2  2025-02-11 08:00:00            0.4      sad\n",
            "5  employee_2  2025-02-12 08:00:00            0.4      sad\n",
            "6  employee_2  2025-02-13 08:00:00            0.4      sad\n",
            "7  employee_2  2025-02-14 08:00:00            0.4      sad\n",
            "8  employee_2  2025-02-15 08:00:00            0.4      sad\n",
            "Failed to send email. Error: (535, b'5.7.8 Username and Password not accepted. For more information, go to\\n5.7.8  https://support.google.com/mail/?p=BadCredentials d2e1a72fcca58-7328371e36esm7046072b3a.61 - gsmtp')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "\n",
        "# Sample Data Frame to simulate mood data collection with prolonged stress for employee_2\n",
        "data = {\n",
        "    \"employee_id\": ['employee_1', 'employee_1', 'employee_1', 'employee_2', 'employee_2', 'employee_2', 'employee_2', 'employee_2', 'employee_2'],\n",
        "    \"timestamp\": [\n",
        "        \"2025-02-10 08:00:00\", \"2025-02-11 08:00:00\", \"2025-02-12 08:00:00\",\n",
        "        \"2025-02-10 08:00:00\", \"2025-02-11 08:00:00\", \"2025-02-12 08:00:00\",\n",
        "        \"2025-02-13 08:00:00\", \"2025-02-14 08:00:00\", \"2025-02-15 08:00:00\"\n",
        "    ],\n",
        "    \"emotion_score\": [0.8, 0.6, 0.7, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4],\n",
        "    \"emotion\": ['happy', 'neutral', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample Data Frame:\")\n",
        "print(df)\n",
        "\n",
        "# Function to analyze mood data for a specific employee\n",
        "def analyze_mood_data(df, employee_id):\n",
        "    employee_data = df[df['employee_id'] == employee_id]\n",
        "    return employee_data\n",
        "\n",
        "# Function to detect prolonged stress or disengagement\n",
        "def detect_stress(employee_data, threshold=0.5, prolonged_days=3):\n",
        "    # Convert timestamp to datetime using .loc to avoid SettingWithCopyWarning\n",
        "    employee_data.loc[:, 'timestamp'] = pd.to_datetime(employee_data['timestamp'])\n",
        "    # Sort data by timestamp\n",
        "    employee_data = employee_data.sort_values('timestamp')\n",
        "\n",
        "    # Identify days with emotion scores below the threshold\n",
        "    stressed_days = employee_data[employee_data['emotion_score'] < threshold]\n",
        "\n",
        "    # Check if prolonged stress or disengagement is detected\n",
        "    if len(stressed_days) >= prolonged_days:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# Function to send email\n",
        "def send_email(to_email, subject, message):\n",
        "    from_email = \"mohammedkn1302@gmail.com\"\n",
        "    from_password = \"aseelbhavana\"  # Use App Password if 2FA is enabled\n",
        "\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] = from_email\n",
        "    msg['To'] = to_email\n",
        "    msg['Subject'] = subject\n",
        "\n",
        "    msg.attach(MIMEText(message, 'plain'))\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP('smtp.gmail.com', 587)  # Gmail's SMTP server address\n",
        "        server.starttls()\n",
        "        server.login(from_email, from_password)\n",
        "        text = msg.as_string()\n",
        "        server.sendmail(from_email, to_email, text)\n",
        "        server.quit()\n",
        "        print(f\"Email sent to {to_email}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to send email. Error: {e}\")\n",
        "\n",
        "# Function to send notifications to HR or managers\n",
        "def send_notification(employee_id):\n",
        "    hr_email = \"mohammedaseel0786@gmail.com\"  # Replace with HR's email address\n",
        "    subject = f\"Prolonged Stress Alert for {employee_id}\"\n",
        "    message = f\"Alert: Prolonged stress detected for {employee_id}. Please take necessary actions.\"\n",
        "    send_email(hr_email, subject, message)\n",
        "\n",
        "# Example usage for employee_1\n",
        "employee_1_data = analyze_mood_data(df, 'employee_1')\n",
        "if detect_stress(employee_1_data):\n",
        "    send_notification('employee_1')\n",
        "\n",
        "# Example usage for employee_2\n",
        "employee_2_data = analyze_mood_data(df, 'employee_2')\n",
        "if detect_stress(employee_2_data):\n",
        "    send_notification('employee_2')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXmj4rSISb16",
        "outputId": "d3656f05-325d-4cf1-8171-1b808ea13dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Data Frame:\n",
            "  employee_id            timestamp  emotion_score  emotion\n",
            "0  employee_1  2025-02-10 08:00:00            0.8    happy\n",
            "1  employee_1  2025-02-11 08:00:00            0.6  neutral\n",
            "2  employee_1  2025-02-12 08:00:00            0.7    happy\n",
            "3  employee_2  2025-02-10 08:00:00            0.4      sad\n",
            "4  employee_2  2025-02-11 08:00:00            0.4      sad\n",
            "5  employee_2  2025-02-12 08:00:00            0.4      sad\n",
            "6  employee_2  2025-02-13 08:00:00            0.4      sad\n",
            "7  employee_2  2025-02-14 08:00:00            0.4      sad\n",
            "8  employee_2  2025-02-15 08:00:00            0.4      sad\n",
            "Failed to send email. Error: (535, b'5.7.8 Username and Password not accepted. For more information, go to\\n5.7.8  https://support.google.com/mail/?p=BadCredentials af79cd13be357-7c09d6c5c4asm697702485a.78 - gsmtp')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "\n",
        "# Function to send email\n",
        "def send_email(to_email, subject, message):\n",
        "    from_email = \"mohammedkn1302@gmail.com\"\n",
        "    from_password = \"aseelbhavana\"  # Use App Password if 2FA is enabled\n",
        "\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] = from_email\n",
        "    msg['To'] = to_email\n",
        "    msg['Subject'] = subject\n",
        "\n",
        "    msg.attach(MIMEText(message, 'plain'))\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP('smtp.gmail.com', 587)  # Gmail's SMTP server address\n",
        "        server.starttls()\n",
        "        server.login(from_email, from_password)\n",
        "        text = msg.as_string()\n",
        "        server.sendmail(from_email, to_email, text)\n",
        "        server.quit()\n",
        "        print(f\"Email sent to {to_email}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to send email. Error: {e}\")\n",
        "\n",
        "# Example usage\n",
        "send_email(\"mohammedaseel0786@gmail.com\", \"Prolonged Stress Alert for employee_1\", \"Alert: Prolonged stress detected for employee_1. Please take necessary actions.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCW0RFb2TIqx",
        "outputId": "e647a8c4-e746-4ddc-eecc-26f2f7f7402d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to send email. Error: (535, b'5.7.8 Username and Password not accepted. For more information, go to\\n5.7.8  https://support.google.com/mail/?p=BadCredentials 6a1803df08f44-6e65d9f459asm105063176d6.70 - gsmtp')\n"
          ]
        }
      ]
    }
  ]
}